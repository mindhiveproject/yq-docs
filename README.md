# ðŸ‘‹ You: Quantified in the Classroom

## Overview

{% embed url="https://files.gitbook.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2Fb3rCB59rniuhUG8KgeGI%2Fuploads%2FtmUAhocXO6R1p5VCwRmq%2FYou%20Quantified%20%E2%80%93%20Program%20Presentation.mp4?alt=media&token=edc437aa-03e1-4d08-aee5-1b5c615070cd" %}

### Platform

**You: Quantified** gives middle and high school students the opportunity to explore data generated by their own brains, bodies, and behavior. With the support of hands-on lessons that introduce them to basic principles of data, creative data visualization, and data ethics, learners will work with biosensing devices and web-based creative coding tools to develop their own representations of their brainwaves, heart rate, voice, etc. They pursue their own research questions and curiosity about the data they generate, contextualize their observations within population-wide patterns, and discover ways in which data plays a role across a range of STEM/STEAM careers by connecting with professionals who work with human data.

{% hint style="info" %}
Currently, the app has restricted access. You can join the waitlist at [youquantified.app](https://youquantified.app/) or reach out directly to us via email at youquantified@nyu.edu
{% endhint %}

### Curriculum

Alongside the platform, we are developing an educational curriculum that uses this application as a learning tool and covers topics such as data, bio-sensing, social synchrony, and artificial intelligence.

* You can find more information in the [educational resources](educational-resources.md) section of this guide.

## Platform usage

If this is your first time visiting the platform, please check out our [quick start guide](quick-start.md).&#x20;

{% content-ref url="quick-start.md" %}
[quick-start.md](quick-start.md)
{% endcontent-ref %}

### Summary of devices

Below, we provide a summary of the devices that may be used with the web application. Some of them may require the purchase of separate hardware while others may be used with your computer's webcam or microphone. You can find more information under the [supported devices](broken-reference) tab.

<table data-view="cards" data-full-width="false"><thead><tr><th>Device</th><th>What does it stream?</th><th>Pre-requirements</th><th data-type="content-ref"></th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>File upload</strong></td><td>Pre-recorded data</td><td>A previous recording with the app.</td><td></td><td><a href="devices/file-upload.md">file-upload.md</a></td></tr><tr><td><strong>Face Landmarks</strong></td><td>Facial expression metrics</td><td>Camera</td><td></td><td><a href="devices/face-landmarks.md">face-landmarks.md</a></td></tr><tr><td><strong>Video Heart Rate</strong></td><td>Heart rate</td><td>Camera</td><td></td><td><a href="devices/video-heart-rate.md">video-heart-rate.md</a></td></tr><tr><td><strong>Audio Volume</strong></td><td>Ambient noise levels</td><td>Microphone</td><td></td><td></td></tr><tr><td><strong>Muse</strong></td><td><p>EEG &#x26; bandpower</p><p>PPG &#x26; heart rate</p></td><td>Muse 2 hardware</td><td></td><td><a href="devices/muse.md">muse.md</a></td></tr><tr><td><strong>EMOTIV</strong></td><td>EEG &#x26; band power</td><td>EMOTIV-hardware</td><td></td><td><a href="devices/emotiv.md">emotiv.md</a></td></tr><tr><td><strong>LSL</strong></td><td>Multiple types of streams</td><td>LSL-Compatible Scientific Equipment</td><td></td><td></td></tr></tbody></table>

## Contributing to development

This app was built as an open-source platform. For project maintenance and documentation, you may find some information in the developer's section of this guide and check out the full code powering the web application at the following GitHub.

{% embed url="https://github.com/esromerog/You-Quantified/tree/main" %}

As an open-source platform, this app leverages other technologies, such as [P5.js](https://p5js.org). You may find more information as you dive into this documentation.

### About us & Credits

This app was developed at NYU through a collaboration of multiple research laboratories as a project aimed at promoting studentsâ€™ data literacy through their creative representation of the Quantified Self.  &#x20;

Our team is also responsible for the development, maintenance, and implementation of the [MindHive platform](https://mindhive.science).

This project is led by [Suzanne Dikker](http://www.suzannedikker.net), [Camillia Matuk](https://wp.nyu.edu/riddle/), and [Xavier Ochoa](https://steinhardt.nyu.edu/people/xavier-ochoa) at New York University with support from the National Science Foundation.&#x20;



&#x20;



